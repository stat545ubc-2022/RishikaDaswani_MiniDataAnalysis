
---
title: "Mini Data-Analysis Deliverable 1"
output: github_document
---

# Welcome to your (maybe) first-ever data analysis project!

And hopefully the first of many. Let's get started:

1.  Install the [`datateachr`](https://github.com/UBC-MDS/datateachr) package by typing the following into your **R terminal**:

<!-- -->

    install.packages("devtools")
    devtools::install_github("UBC-MDS/datateachr")
    

2.  Load the packages below.

```{r}
library(datateachr)
library(tidyverse)
```

3.  Make a repository in the <https://github.com/stat545ubc-2022> Organization. You will be working with this repository for the entire data analysis project. You can either make it public, or make it private and add the TA's and Lucy as collaborators. A link to help you create a private repository is available on the #collaborative-project Slack channel. 

# Instructions

## For Both Milestones

-   Each milestone is worth 45 points. The number of points allocated to each task will be annotated within each deliverable. Tasks that are more challenging will often be allocated more points.

-   10 points will be allocated to the reproducibility, cleanliness, and coherence of the overall analysis. While the two milestones will be submitted as independent deliverables, the analysis itself is a continuum - think of it as two chapters to a story. Each chapter, or in this case, portion of your analysis, should be easily followed through by someone unfamiliar with the content. [Here](https://swcarpentry.github.io/r-novice-inflammation/06-best-practices-R/) is a good resource for what constitutes "good code". Learning good coding practices early in your career will save you hassle later on!

## For Milestone 1

**To complete this milestone**, edit [this very `.Rmd` file](https://raw.githubusercontent.com/UBC-STAT/stat545.stat.ubc.ca/master/content/mini-project/mini-project-1.Rmd) directly. Fill in the sections that are tagged with `<!--- start your work below --->`.

**To submit this milestone**, make sure to knit this `.Rmd` file to an `.md` file by changing the YAML output settings from `output: html_document` to `output: github_document`. Commit and push all of your work to the mini-analysis GitHub repository you made earlier, and tag a release on GitHub. Then, submit a link to your tagged release on canvas.

**Points**: This milestone is worth 45 points: 43 for your analysis, 1 point for having your Milestone 1 document knit error-free, and 1 point for tagging your release on Github.

# Learning Objectives

By the end of this milestone, you should:

-   Become familiar with your dataset of choosing
-   Select 4 questions that you would like to answer with your data
-   Generate a reproducible and clear report using R Markdown
-   Become familiar with manipulating and summarizing your data in tibbles using `dplyr`, with a research question in mind.

# Task 1: Choose your favorite dataset (10 points)

The `datateachr` package by Hayley Boyce and Jordan Bourak currently composed of 7 semi-tidy datasets for educational purposes. Here is a brief description of each dataset:

-   *apt_buildings*: Acquired courtesy of The City of Toronto's Open Data Portal. It currently has 3455 rows and 37 columns.

-   *building_permits*: Acquired courtesy of The City of Vancouver's Open Data Portal. It currently has 20680 rows and 14 columns.

-   *cancer_sample*: Acquired courtesy of UCI Machine Learning Repository. It currently has 569 rows and 32 columns.

-   *flow_sample*: Acquired courtesy of The Government of Canada's Historical Hydrometric Database. It currently has 218 rows and 7 columns.

-   *parking_meters*: Acquired courtesy of The City of Vancouver's Open Data Portal. It currently has 10032 rows and 22 columns.

-   *steam_games*: Acquired courtesy of Kaggle. It currently has 40833 rows and 21 columns.

-   *vancouver_trees*: Acquired courtesy of The City of Vancouver's Open Data Portal. It currently has 146611 rows and 20 columns.

**Things to keep in mind**

-   We hope that this project will serve as practice for carrying our your own *independent* data analysis. Remember to comment your code, be explicit about what you are doing, and write notes in this markdown document when you feel that context is required. As you advance in the project, prompts and hints to do this will be diminished - it'll be up to you!

-   Before choosing a dataset, you should always keep in mind **your goal**, or in other ways, *what you wish to achieve with this data*. This mini data-analysis project focuses on *data wrangling*, *tidying*, and *visualization*. In short, it's a way for you to get your feet wet with exploring data on your own.

And that is exactly the first thing that you will do!

1.1 Out of the 7 datasets available in the `datateachr` package, choose **4** that appeal to you based on their description. Write your choices below:

**Note**: We encourage you to use the ones in the `datateachr` package, but if you have a dataset that you'd really like to use, you can include it here. But, please check with a member of the teaching team to see whether the dataset is of appropriate complexity. Also, include a **brief** description of the dataset here to help the teaching team understand your data.

<!-------------------------- Start your work below ---------------------------->

1: apt_buildings
2: cancer_sample
3: parking_meters
4: vancouver_trees

<!----------------------------------------------------------------------------->

1.2 One way to narrowing down your selection is to *explore* the datasets. Use your knowledge of dplyr to find out at least *3* attributes about each of these datasets (an attribute is something such as number of rows, variables, class type...). The goal here is to have an idea of *what the data looks like*.

*Hint:* This is one of those times when you should think about the cleanliness of your analysis. I added a single code chunk for you below, but do you want to use more than one? Would you like to write more comments outside of the code chunk?

<!-------------------------- Start your work below ---------------------------->

```{r}
### EXPLORE HERE ###
#apt_buildings attributes: It is a tibble with 37 columns, 3,455 rows and observations are mostly character vectors 
glimpse(apt_buildings)
head(apt_buildings)
class(apt_buildings)

#cancer_sample attributes: It is a tibble with 32 columns, 569 rows and observations are all double vectors containing real numbers except diagnosis column which is a character vector. This dataset is actually a tibble subclass (spec_tbl_df) and it differs from a regular tibble in that the spec attribute (which holds the column specification) is lost as soon as the object is a subset. 
glimpse(cancer_sample)
head(cancer_sample)
class(cancer_sample)

#parking_meters attributes: It is a tibble with 22 columns, 10,032 rows and observations are mostly character vectors. 
glimpse(parking_meters)
head(parking_meters)
class(parking_meters)
typeof(parking_meters)

#vancouver_trees attributes: It is a tibble with 20 columns, 146,611 rows and observations are a mix of character and double vectors. 
glimpse(vancouver_trees)
head(vancouver_trees)
class(vancouver_trees)
typeof(vancouver_trees)
summary(vancouver_trees)
```

<!----------------------------------------------------------------------------->

1.3 Now that you've explored the 4 datasets that you were initially most interested in, let's narrow it down to 2. What lead you to choose these 2? Briefly explain your choices below, and feel free to include any code in your explanation.

<!-------------------------- Start your work below ---------------------------->
The two datasets that I have narrowed down to are; The vancouver_trees dataset and the cancer_sample dataset. I chose these two datasets as I can pin-point a target 'population' of interest quite easily. Whether it is looking at one species of tree or one type of diagnosis for the cancer cells (either malignant or benign). In addition, due to the large nature of the datasets, it can be manipulated to answer a variety of research questions. 
<!----------------------------------------------------------------------------->

1.4 Time for the final decision! Going back to the beginning, it's important to have an *end goal* in mind. For example, if I had chosen the `titanic` dataset for my project, I might've wanted to explore the relationship between survival and other variables. Try to think of 1 research question that you would want to answer with each dataset. Note them down below, and make your final choice based on what seems more interesting to you!

<!-------------------------- Start your work below ---------------------------->
**Research Questions** 
Vancouver Trees Research Question: Does the presence of a curb negatively impact the tree diameter? (smaller tree diameter) 
Cancer Sample Research Question: Does the radius of the nuclei have an effect on the diagnosis of the cancer? (malignant or benign)

My final choice will be to work with the Vancouver Trees Dataset. 
<!----------------------------------------------------------------------------->

# Important note

Read Tasks 2 and 3 *fully* before starting to complete either of them. Probably also a good point to grab a coffee to get ready for the fun part!

This project is semi-guided, but meant to be *independent*. For this reason, you will complete tasks 2 and 3 below (under the **START HERE** mark) as if you were writing your own exploratory data analysis report, and this guidance never existed! Feel free to add a brief introduction section to your project, format the document with markdown syntax as you deem appropriate, and structure the analysis as you deem appropriate. Remember, marks will be awarded for completion of the 4 tasks, but 10 points of the whole project are allocated to a reproducible and clean analysis. If you feel lost, you can find a sample data analysis [here](https://www.kaggle.com/headsortails/tidy-titarnic) to have a better idea. However, bear in mind that it is **just an example** and you will not be required to have that level of complexity in your project.

# Task 2: Exploring your dataset (15 points)

If we rewind and go back to the learning objectives, you'll see that by the end of this deliverable, you should have formulated *4* research questions about your data that you may want to answer during your project. However, it may be handy to do some more exploration on your dataset of choice before creating these questions - by looking at the data, you may get more ideas. **Before you start this task, read all instructions carefully until you reach START HERE under Task 3**.

2.1 Complete *4 out of the following 8 exercises* to dive deeper into your data. All datasets are different and therefore, not all of these tasks may make sense for your data - which is why you should only answer *4*. Use *dplyr* and *ggplot*.

1.  Plot the distribution of a numeric variable.
2.  Create a new variable based on other variables in your data (only if it makes sense)
3.  Investigate how many missing values there are per variable. Can you find a way to plot this?
4.  Explore the relationship between 2 variables in a plot.
5.  Filter observations in your data according to your own criteria. Think of what you'd like to explore - again, if this was the `titanic` dataset, I may want to narrow my search down to passengers born in a particular year...
6.  Use a boxplot to look at the frequency of different observations within a single variable. You can do this for more than one variable if you wish!
7.  Make a new tibble with a subset of your data, with variables and observations that you are interested in exploring.
8.  Use a density plot to explore any of your variables (that are suitable for this type of plot).

2.2 For each of the 4 exercises that you complete, provide a *brief explanation* of why you chose that exercise in relation to your data (in other words, why does it make sense to do that?), and sufficient comments for a reader to understand your reasoning and code.

<!-------------------------- Start your work below ---------------------------->

<!----------------------------------------------------------------------------->

# Task 3: Write your research questions (5 points)

So far, you have chosen a dataset and gotten familiar with it through exploring the data. Now it's time to figure out 4 research questions that you would like to answer with your data! Write the 4 questions and any additional comments at the end of this deliverable. These questions are not necessarily set in stone - TAs will review them and give you feedback; therefore, you may choose to pursue them as they are for the rest of the project, or make modifications!

<!--- *****START HERE***** --->

## Task 2: Exploring the Dataset 

I will be completing the following exercises: 1, 3, 4 and 5. 

1. Plot the distribution of a numeric variable: I will be exploring the distribution of tree diameter
```{r}
ggplot(vancouver_trees, aes(diameter)) + 
  geom_histogram(fill = "white", colour = "blue", bins = 40) + scale_x_log10()

ggplot(vancouver_trees, aes(diameter)) + geom_histogram(binwidth = 5)

#I am using coord_cartesian function to show a zoomed in version of the plot since there are some outlier data points that do not allow you to view the distribution properly 
ggplot(vancouver_trees, aes(diameter)) + geom_histogram(binwidth = 5) + coord_cartesian(xlim = c(0, 100))
```

3. Investigate how many missing values there are per variable. Can you find a way to plot this?
```{r}
#Are there missing values in the variables I am interested in? 
any(is.na(vancouver_trees$diameter))
any(is.na(vancouver_trees$curb))
#as we can see there are no NA values in the variables I am interested in exploring. 

#To find missing values in other variables 
NA_values <- vancouver_trees %>% summarise(across(everything(), ~sum(is.na(.)))) 
print(NA_values)

#There are NA values in the following variables: cultivar_name, plant_area, date_planted, longitude and latitude. 

#Select the columns that have NA values and then plot them
Target_NA_values <- NA_values %>% select(cultivar_name, plant_area, date_planted, longitude, latitude)
print(Target_NA_values)

Target_NA_values %>% pivot_longer(cols=everything()) %>%
  ggplot(aes(x=name, y=value)) + geom_col() + xlab("Variable")+ ylab("Number of Missing Entries")
```

4. Explore the relationship between 2 variables in a plot: count how many trees are planted near a curb versus ones that are not planted near a curb and then plot the diameter to show distribution of trees diameter with curb and without curb
```{r}
count(vancouver_trees, curb)
#133807	trees planted in the presence of a curb and 12804 trees with no curb presence.

ggplot(vancouver_trees, aes(curb, diameter)) + geom_jitter(alpha = 0.1) + scale_y_log10()
```


5. Filter observations in your data according to your own criteria: Filtering the data with regards to presence or no presence of curb and filtering to give only the variable I am interested in, Diameter. 
```{r}
curb_yes <- filter(vancouver_trees, curb == "Y")
curb_no <- filter(vancouver_trees, curb == "N")

glimpse(curb_yes$diameter)
glimpse(curb_no$diameter)
```

## Task 3: Write Your Research Questions
1. Does the presence of a curb negatively impact the diameter of the trees? i.e. Do trees have a smaller average diameter in the presence of a curb? 
2. Does the presence of a curb negatively impact the height range of the trees? i.e. Do trees have a smaller height range in the presence of a curb? 
3. Does genus have an affect on the diameter of the tree? i.e. is there a particular genera with larger tree diameter compared to other genera? 
4. Does having a root barrier negatively impact the diameter of the trees? i.e. Do trees have a smaller average diameter if there is a root barrier?  

# Task 4: Process and summarize your data (13 points)

From Task 2, you should have an idea of the basic structure of your dataset (e.g. number of rows and columns, class types, etc.). Here, we will start investigating your data more in-depth using various data manipulation functions.

### 1.1 (10 points)

Now, for each of your four research questions, choose one task from options 1-4 (summarizing), and one other task from 4-8 (graphing). You should have 2 tasks done for each research question (8 total). Make sure it makes sense to do them! (e.g. don't use a numerical variables for a task that needs a categorical variable.). Comment on why each task helps (or doesn't!) answer the corresponding research question.

Ensure that the output of each operation is printed!

**Summarizing:**

1.  Compute the *range*, *mean*, and *two other summary statistics* of **one numerical variable** across the groups of **one categorical variable** from your data.
2.  Compute the number of observations for at least one of your categorical variables. Do not use the function `table()`!
3.  Create a categorical variable with 3 or more groups from an existing numerical variable. You can use this new variable in the other tasks! *An example: age in years into "child, teen, adult, senior".*
4.  Based on two categorical variables, calculate two summary statistics of your choosing.

**Graphing:**

5.  Create a graph out of summarized variables that has at least two geom layers.
6.  Create a graph of your choosing, make one of the axes logarithmic, and format the axes labels so that they are "pretty" or easier to read.
7.  Make a graph where it makes sense to customize the alpha transparency.
8.  Create 3 histograms out of summarized variables, with each histogram having different sized bins. Pick the "best" one and explain why it is the best.

Make sure it's clear what research question you are doing each operation for!

<!------------------------- Start your work below ----------------------------->

**Question 1: Does the presence of a curb negatively impact the diameter of the trees? i.e. Do trees have a smaller average diameter in the presence of a curb?** 

Summarizing Task 1
```{r}
#finding range of diameters for trees with curb 
range_diameters <-range(curb_yes$diameter)
print(range_diameters)
#finding mean of diameters for trees with curb 
mean_diameters <- mean(curb_yes$diameter)
print(mean_diameters)
#finding standard deviation of diameters for trees with curb
stddeviation_diameters <- sd(curb_yes$diameter)
print(stddeviation_diameters)
#finding median diameter of trees with curb
median_diameter <- median(curb_yes$diameter)
print(median_diameter)

#OR we can use the summary function to find out min, max, mean, median, 1st quartile and second quartile 
summary(curb_yes$diameter)
summary(curb_no$diameter)

#from this summarizing exercise, we can see that there is a higher mean and median diameter of trees not near a curb compared to trees near a curb.
```

Graphing Task 8 
```{r}
ggplot(curb_yes, aes(diameter)) + geom_histogram(bins = 15)
ggplot(curb_yes, aes(diameter)) + geom_histogram(bins = 25)
ggplot(curb_yes, aes(diameter)) + geom_histogram(bins = 40)

#Here I have plotted the diameter of trees planted near a curb using different sized bins. We can see that a larger bin size of around 40 enables us to see the pattern of the data better. 
```
**Question 2: Does the presence of a curb negatively impact the height range of the trees? i.e. Do trees have a smaller height range in the presence of a curb?** 

Summarizing Task 2
```{r}
#Compute number of observations for all the height ranges (0= 0-10 ft, 1= 1-10 ft, 2= 20-30 ft, 3= 3-40 ft and so on till 10= 100+ ft) for the curb_yes subset and the curb_no subset 
curb_yes$height_range_id <- as.factor(curb_yes$height_range_id)
summary(curb_yes$height_range_id)

curb_no$height_range_id <- as.factor(curb_no$height_range_id)
summary(curb_no$height_range_id)

#From this summarizing exercise we can see that as we get to the higher height ranges (70-100+ ft) the number of observations become less in the curb_no than in the curb_yes. Showing us that there are fewer taller trees where there is no curb present compared to where the curb is present. This could be just due to the fact that there are fewer trees in general in the curb_no subset. Which we can see clearly in Task 2, exercise 4.  

```

Graphing Task 5
```{r}
ggplot(vancouver_trees, aes(curb, height_range_id)) + geom_boxplot() + geom_count()
#Through plotting the data on a boxplot, you can actually see that there is not much different in height range between curb and no curb subsets. Through adding the geom_count() layer you can also see that there are some outliers in the dataset. 
```
**Question 3: Does genus affect the diameter of the tree? i.e. is there a particular genus with larger tree diameter?** 

Summarizing Task 1
```{r}
#After trying to complete this task for all genus, I realized that there are too many and it would make sense to select only a few genera and complete the analysis on that. So first I will filter the dataset to narrow it down to only 5 randomly selected genera. 

vancouver_trees_genus <- vancouver_trees %>% filter(genus_name %in% c("NYSSA", "FAGUS", "ACER", "POPULUS", "MAGNOLIA"))
vancouver_trees_genus

#Finding the mean, range, standard deviation and median diameters for each of the genus selected. 
vancouver_trees_summary <- vancouver_trees_genus %>% select(genus_name, diameter) %>% group_by(genus_name) %>% 
  summarize(diam_mean = mean(diameter), range_diam = range(diameter), diam_sd = sd(diameter), diam_median = median(diameter))

#We can see that there are two columns for each genera as there is a min and max given for the range. 

```

Graphing Task 6
```{r}
vancouver_trees_genus %>% select(genus_name, diameter) %>%
  filter(genus_name == "MAGNOLIA") %>% ggplot(aes(diameter)) + geom_histogram(binwidth = 3, color = "white") + scale_y_log10() +xlab("Log of Diameter") + ggtitle("Distribution of Log of Diameters of Magnolia Trees")

vancouver_trees_genus %>% select(genus_name, diameter) %>%
  filter(genus_name == "FAGUS") %>% ggplot(aes(diameter)) + geom_histogram(binwidth = 3, color = "white") + scale_y_log10() +xlab("Log of Diameter") + ggtitle("Distribution of Log of Diameters of Fagus Trees")

```

**Question 4: Does having a root barrier negatively impact the diameter of the trees? i.e. Do trees have a smaller average diameter if there is a root barrier?** 

Summarizing Task 1
```{r}
rootbarrier_yes <- filter(vancouver_trees, root_barrier == "Y")
rootbarrier_no <- filter(vancouver_trees, root_barrier == "N")

#finding range of diameters for trees with root barrier
range_diameters_rootbarrier <-range(rootbarrier_yes$diameter)
print(range_diameters_rootbarrier)
#finding mean of diameters for trees with root barrier
mean_diameters_rootbarrier <- mean(rootbarrier_yes$diameter)
print(mean_diameters_rootbarrier)
#finding standard deviation of diameters for trees with root barrier
stddeviation_diameters_rootbarrier <- sd(rootbarrier_yes$diameter)
print(stddeviation_diameters_rootbarrier)
#finding median diameter of trees with root barrier
median_diameter_rootbarrier <- median(rootbarrier_yes$diameter)
print(median_diameter_rootbarrier)

#OR we can use the summary function to find out min, max, mean, median, 1st quartile and second quartile of both groups (trees with and without root barrier)
summary(rootbarrier_yes$diameter)
summary(rootbarrier_no$diameter)

#From this summarizing exercise, we have found that trees without root barriers have a larger average diameter compared to trees with root barriers. Additionally, the maximum diameter of trees without root barriers is much higher than the maximum diameter of trees with root barriers.
```

Graphing Task 6
```{r}
ggplot(vancouver_trees, aes(x = root_barrier, y = diameter, color=root_barrier)) + xlab("Root Barrier") + ylab("log of Diameter") + geom_point(alpha = 0.5) + scale_y_continuous(trans='log10') + scale_fill_discrete(name = "Root Barrier") + ggtitle("Log of Diameter by Root Barrier")

```


<!----------------------------------------------------------------------------->

### 1.2 (3 points)

Based on the operations that you've completed, how much closer are you to answering your research questions? Think about what aspects of your research questions remain unclear. Can your research questions be refined, now that you've investigated your data a bit more? Which research questions are yielding interesting results?

<!-------------------------- Start your work below ---------------------------->
Through this exploration, I have got a good understanding of the dataset and the observations. First, I looked at whether presence of curb and root barrier affects the diameter of the tree and through my analysis I am closer to answering this question. I was able to note a higher mean and median diameter of trees that were planted not in presence of a curb compared to trees that had a curb. In addition to this, I also noted that trees with no root barrier have a higher mean and median diameter and a larger maximum diameter value compared to trees with root barriers. So we can see that both presence of curb and root barrier have an affect on the diameter. 

Secondly, I selected 5 random genera and looked at whether genera has an effect on diameter. From my sample, I could tell that the Populus tree has the largest average diameter whereas the Nyssa trees has the smallest average diameter. I believe that more analysis can go into this question. 

Further exploration could be done with regards to particular species. After this analysis, I might want to refine my research question by only looking at one genera or species and the different cultivar varieties it has. Question 3 and 4 seem the most interesting if I narrow it down. I would like to explore the correlation, if any - to do this I try computing a logistic regression.  
<!----------------------------------------------------------------------------->

### Attribution

Thanks to Icíar Fernández Boyano for mostly putting this together, and Vincenzo Coia for launching.
